!pip install requests beautifulsoup4 fake-useragent lxml pandas

import requests
from bs4 import BeautifulSoup
import time
import random
from fake_useragent import UserAgent
import json
from urllib.parse import urlencode, urlparse
import re
import pandas as pd
from datetime import datetime

def get_stealth_headers():
    """
    Botæ¤œå‡ºã‚’å›é¿ã™ã‚‹ãŸã‚ã®ãƒªã‚¢ãƒ«ãªãƒ˜ãƒƒãƒ€ãƒ¼
    """
    ua = UserAgent()
    
    return {
        'User-Agent': ua.chrome,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9,ja;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Cache-Control': 'max-age=0',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'same-origin',
        'Sec-Fetch-User': '?1',
        'Referer': 'https://www.ebay.com/',
    }

def get_ebay_session():
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¨ã‚¯ãƒƒã‚­ãƒ¼ã‚’å–å¾—
    """
    session = requests.Session()
    session.headers.update(get_stealth_headers())
    
    # ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã‚¯ãƒƒã‚­ãƒ¼ã‚’å–å¾—
    try:
        response = session.get('https://www.ebay.com', timeout=10)
        print(f"ğŸª ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹: {response.status_code}")
        time.sleep(random.uniform(1, 3))
        return session
    except Exception as e:
        print(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def extract_price_from_text(text):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ä¾¡æ ¼ã‚’æŠ½å‡ºã—ã€é©åˆ‡ãªé€šè²¨æ›ç®—ã‚’è¡Œã†æ”¹è‰¯ç‰ˆé–¢æ•°
    """
    if not text:
        return "ä¾¡æ ¼ä¸æ˜"
    
    # é€šè²¨åˆ¥ãƒ¬ãƒ¼ãƒˆï¼ˆ2024å¹´åŸºæº–ã®æ¦‚ç®—ãƒ¬ãƒ¼ãƒˆï¼‰
    # å®Ÿéš›ã®é‹ç”¨ã§ã¯ç‚ºæ›¿APIã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨
    rates = {
        "NT$": 0.032,   # å°æ¹¾ãƒ‰ãƒ« â†’ USD (1 TWD â‰ˆ 0.032 USD)
        "HK$": 0.13,    # é¦™æ¸¯ãƒ‰ãƒ« â†’ USD (1 HKD â‰ˆ 0.13 USD) 
        "Â¥": 0.0067,    # æ—¥æœ¬å†† â†’ USD (1 JPY â‰ˆ 0.0067 USD)
        "â‚¬": 1.08,      # ãƒ¦ãƒ¼ãƒ­ â†’ USD (1 EUR â‰ˆ 1.08 USD)
        "Â£": 1.25,      # è‹±ãƒãƒ³ãƒ‰ â†’ USD (1 GBP â‰ˆ 1.25 USD)
        "$": 1.0,       # ç±³ãƒ‰ãƒ«ï¼ˆåŸºæº–é€šè²¨ï¼‰
        "USD": 1.0      # æ˜ç¤ºçš„ãªUSDè¡¨è¨˜
    }
    
    # é€šè²¨è¨˜å·ä»˜ãã®ä¾¡æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå„ªå…ˆåº¦é †ï¼‰
    currency_patterns = [
        # å°æ¹¾ãƒ‰ãƒ«ï¼ˆNT$ï¼‰- eBayã§ã‚ˆãè¦‹ã‚‰ã‚Œã‚‹
        r'NT\$\s*([\d,]+(?:\.\d{1,2})?)',
        # é¦™æ¸¯ãƒ‰ãƒ«ï¼ˆHK$ï¼‰
        r'HK\$\s*([\d,]+(?:\.\d{1,2})?)',
        # æ—¥æœ¬å††ï¼ˆÂ¥ï¼‰
        r'Â¥\s*([\d,]+(?:\.\d{1,2})?)',
        # ãƒ¦ãƒ¼ãƒ­ï¼ˆâ‚¬ï¼‰
        r'â‚¬\s*([\d,]+(?:\.\d{1,2})?)',
        # è‹±ãƒãƒ³ãƒ‰ï¼ˆÂ£ï¼‰
        r'Â£\s*([\d,]+(?:\.\d{1,2})?)',
        # ç±³ãƒ‰ãƒ«ï¼ˆ$ï¼‰- æœ€å¾Œã«å‡¦ç†ï¼ˆä»–ã®é€šè²¨ã¨æ··åŒã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
        r'(?<!NT)(?<!HK)\$\s*([\d,]+(?:\.\d{1,2})?)',
        # USDæ˜ç¤º
        r'USD\s*([\d,]+(?:\.\d{1,2})?)',
        r'([\d,]+(?:\.\d{1,2})?)\s*USD'
    ]
    
    # é€šè²¨è¨˜å·ã«å¯¾å¿œã™ã‚‹è­˜åˆ¥å­
    currency_symbols = ['NT$', 'HK$', 'Â¥', 'â‚¬', 'Â£', '$', 'USD', 'USD']
    
    # å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œ
    for i, pattern in enumerate(currency_patterns):
        matches = re.findall(pattern, text, re.IGNORECASE)
        if matches:
            try:
                # æœ€åˆã«ãƒãƒƒãƒã—ãŸé‡‘é¡ã‚’å–å¾—
                amount_str = matches[0].replace(',', '')
                amount = float(amount_str)
                
                if amount <= 0:
                    continue
                
                # é€šè²¨è¨˜å·ã‚’ç‰¹å®š
                currency = currency_symbols[i]
                
                # ç±³ãƒ‰ãƒ«ã«æ›ç®—
                if currency in rates:
                    usd_amount = amount * rates[currency]
                else:
                    # ä¸æ˜ãªé€šè²¨ã®å ´åˆã¯ãã®ã¾ã¾ï¼ˆç±³ãƒ‰ãƒ«ã¨ä»®å®šï¼‰
                    usd_amount = amount
                
                # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼ˆå¿…è¦ã«å¿œã˜ã¦æœ‰åŠ¹åŒ–ï¼‰
                debug_mode = getattr(extract_price_from_text, 'debug_mode', False)
                if debug_mode:
                    print(f"    ğŸ’° ä¾¡æ ¼å¤‰æ›: {currency}{amount:,} â†’ ${usd_amount:.2f}")
                
                # ç•°å¸¸ã«é«˜é¡ãªä¾¡æ ¼ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆ50ä¸‡ãƒ‰ãƒ«ä»¥ä¸Šã¯ç•°å¸¸å€¤ã¨ã—ã¦æ‰±ã†ï¼‰
                if usd_amount > 500000:
                    if debug_mode:
                        print(f"    âš ï¸  ç•°å¸¸ã«é«˜é¡ãªä¾¡æ ¼ã‚’æ¤œå‡º: {currency}{amount:,} (${usd_amount:.2f}) - ã‚¹ã‚­ãƒƒãƒ—")
                    continue
                
                # ç•°å¸¸ã«å®‰ã„ä¾¡æ ¼ã‚‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆ1ãƒ‰ãƒ«æœªæº€ï¼‰
                if usd_amount < 1.0:
                    continue
                
                return f"${usd_amount:.2f}"
                
            except (ValueError, IndexError):
                continue
    
    # é€šè²¨è¨˜å·ãªã—ã®æ•°å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæœ€å¾Œã®æ‰‹æ®µï¼‰
    number_only_patterns = [
        r'sold\s+for\s+([\d,]+\.?\d*)',
        r'price[:\s]+([\d,]+\.?\d*)',
        r'([\d,]+\.?\d*)\s*(?:dollars?|usd)?'
    ]
    
    for pattern in number_only_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        if matches:
            try:
                amount_str = matches[0].replace(',', '')
                amount = float(amount_str)
                
                # å¦¥å½“ãªä¾¡æ ¼ç¯„å›²ã‹ãƒã‚§ãƒƒã‚¯
                if 1.0 <= amount <= 500000:
                    return f"${amount:.2f}"
            except (ValueError, IndexError):
                continue
    
    return "ä¾¡æ ¼ä¸æ˜"

def extract_item_data(item_element):
    """
    å•†å“è¦ç´ ã‹ã‚‰è©³ç´°æƒ…å ±ã‚’æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆä¾¡æ ¼å‡¦ç†ä»˜ãï¼‰
    """
    try:
        # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        title = "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜"
        
        # æ–¹æ³•1: æ§˜ã€…ãªã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦ã™
        title_selectors = [
            'h3.s-item__title',
            '.s-item__title',
            'h3',
            '.s-item__title-label',
            'a[href*="/itm/"]'
        ]
        
        for selector in title_selectors:
            title_elem = item_element.select_one(selector)
            if title_elem:
                title_text = title_elem.get_text().strip()
                # ä¸è¦ãªæ–‡å­—åˆ—ã‚’é™¤å¤–
                if title_text and len(title_text) > 10 and not any(x in title_text.lower() for x in ['shop on ebay', 'new listing', 'opens in']):
                    title = title_text
                    break
        
        # æ–¹æ³•2: å…¨ã¦ã®aã‚¿ã‚°ã‹ã‚‰ãƒªãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¢ã™
        if title == "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜":
            links = item_element.find_all('a', href=lambda x: x and '/itm/' in x)
            for link in links:
                link_text = link.get_text().strip()
                if len(link_text) > 15 and not any(x in link_text.lower() for x in ['shop on ebay', 'new listing', 'opens in']):
                    title = link_text
                    break
        
        # ä¾¡æ ¼æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        price = "ä¾¡æ ¼ä¸æ˜"
        
        # æ–¹æ³•1: å£²ã‚Šåˆ‡ã‚Œå•†å“ç‰¹æœ‰ã®ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦ã™
        price_selectors = [
            '.s-item__price',
            '.s-item__detail--primary',
            '.s-item__details',
            '.s-item__soldPrice',
            '.sold-price',
            '.s-item__price-soldValue',
            '.notranslate'
        ]
        
        for selector in price_selectors:
            price_elem = item_element.select_one(selector)
            if price_elem:
                price_text = price_elem.get_text().strip()
                extracted_price = extract_price_from_text(price_text)
                if extracted_price != "ä¾¡æ ¼ä¸æ˜":
                    price = extracted_price
                    break
        
        # æ–¹æ³•2: ã‚ˆã‚Šåºƒã„ç¯„å›²ã§ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢
        if price == "ä¾¡æ ¼ä¸æ˜":
            # å•†å“è¦ç´ å…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ä¾¡æ ¼ã‚’æŠ½å‡º
            all_text = item_element.get_text()
            price = extract_price_from_text(all_text)
        
        # æ–¹æ³•3: spanè¦ç´ ã‹ã‚‰ä¾¡æ ¼ã‚’æ¢ã™
        if price == "ä¾¡æ ¼ä¸æ˜":
            spans = item_element.find_all('span')
            for span in spans:
                span_text = span.get_text().strip()
                if any(keyword in span_text.lower() for keyword in ['sold', 'price', '$', 'usd', 'nt$']):
                    extracted_price = extract_price_from_text(span_text)
                    if extracted_price != "ä¾¡æ ¼ä¸æ˜":
                        price = extracted_price
                        break
        
        # å•†å“URLæŠ½å‡º
        link_elem = item_element.select_one('a[href*="/itm/"]')
        url = link_elem.get('href') if link_elem else ""
        
        # ç”»åƒURLæŠ½å‡º
        img_elem = item_element.select_one('img')
        image_url = ""
        if img_elem:
            image_url = img_elem.get('src') or img_elem.get('data-src') or ""
        
        # é€æ–™æƒ…å ±
        shipping_elem = item_element.select_one('.s-item__shipping, .s-item__freeXDays')
        shipping = shipping_elem.get_text().strip() if shipping_elem else ""
        
        # è²©å£²è€…æƒ…å ±
        seller_elem = item_element.select_one('.s-item__seller-info, .s-item__seller-info-text')
        seller = seller_elem.get_text().strip() if seller_elem else ""
        
        # è²©å£²æ—¥æ™‚ï¼ˆå£²ã‚Šåˆ‡ã‚Œå•†å“ã®å ´åˆï¼‰
        sold_elem = item_element.select_one('.s-item__sold-date, .s-item__endedDate, .s-item__detail--primary')
        sold_date = sold_elem.get_text().strip() if sold_elem else ""
        
        # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼ˆæœ€åˆã®æ•°ä»¶ã®ã¿ï¼‰
        if not hasattr(extract_item_data, 'debug_count'):
            extract_item_data.debug_count = 0
        
        if extract_item_data.debug_count < 5:
            print(f"    ğŸ” å•†å“ {extract_item_data.debug_count + 1}:")
            print(f"      ã‚¿ã‚¤ãƒˆãƒ«: {title}")
            print(f"      ä¾¡æ ¼: {price}")
            print(f"      URL: {url[:50]}..." if url else "URLä¸æ˜")
            
            # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šå•†å“è¦ç´ ã®ä¸€éƒ¨ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
            debug_text = item_element.get_text()[:200]
            print(f"      è¦ç´ ãƒ†ã‚­ã‚¹ãƒˆ: {debug_text}...")
            
            extract_item_data.debug_count += 1
        
        return {
            'title': title,
            'price': price,
            'url': url,
            'image_url': image_url,
            'shipping': shipping,
            'seller': seller,
            'sold_date': sold_date,
            'scraped_at': datetime.now().isoformat()
        }
    except Exception as e:
        print(f"âš ï¸ å•†å“ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return None

def search_japanese_items(session, keywords, pages=3):
    """
    å’Œé¢¨å•†å“ã‚’æ¤œç´¢ã—ã¦å–å¾—
    """
    all_items = []
    
    japanese_keywords = [
        "japan vintage", "japanese antique", "kimono", "sake", "sushi", "manga", 
        "anime", "katana", "bonsai", "origami", "zen", "samurai", "geisha",
        "tokyo", "kyoto", "osaka", "nintendo", "sony", "toyota", "honda"
    ]
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
    if not keywords:
        keywords = random.sample(japanese_keywords, min(3, len(japanese_keywords)))
    
    for keyword in keywords:
        print(f"\nğŸ” æ¤œç´¢ä¸­: '{keyword}'")
        
        for page in range(1, pages + 1):
            print(f"  ğŸ“„ ãƒšãƒ¼ã‚¸ {page}/{pages}")
            
            # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            params = {
                '_nkw': keyword,
                'LH_Sold': '1',  # å£²ã‚ŒãŸå•†å“ã®ã¿
                'LH_Complete': '1',  # å®Œäº†ã—ãŸå–å¼•ã®ã¿
                '_sop': '13',  # æœ€è¿‘å£²ã‚ŒãŸé †
                '_ipg': '60',  # ãƒšãƒ¼ã‚¸ã‚ãŸã‚Š60ä»¶
                '_pgn': page
            }
            
            url = f"https://www.ebay.com/sch/i.html?{urlencode(params)}"
            
            try:
                response = session.get(url, timeout=15)
                
                if response.status_code != 200:
                    print(f"    âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                    continue
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # å•†å“è¦ç´ ã‚’å–å¾—
                items = soup.select('li[data-view]')
                
                # åºƒå‘Šã‚„ç„¡é–¢ä¿‚ãªè¦ç´ ã‚’é™¤å¤–
                items = [item for item in items if item.find('a', href=lambda x: x and '/itm/' in x)]
                
                print(f"    âœ… {len(items)}ä»¶ã®å•†å“ã‚’ç™ºè¦‹")
                
                for item in items:
                    item_data = extract_item_data(item)
                    if item_data and item_data['title'] != "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜":
                        all_items.append({**item_data, 'keyword': keyword})
                
                # Botæ¤œå‡ºå›é¿ã®ãŸã‚ã®å¾…æ©Ÿ
                time.sleep(random.uniform(2, 5))
                
            except Exception as e:
                print(f"    âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                continue
    
    return all_items

def filter_japanese_items(items, min_price=5.0):
    """
    å’Œé¢¨å•†å“ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    """
    japanese_indicators = [
        'japan', 'japanese', 'kimono', 'sake', 'sushi', 'manga', 'anime',
        'katana', 'bonsai', 'origami', 'zen', 'samurai', 'geisha', 'tokyo',
        'kyoto', 'osaka', 'vintage', 'antique', 'authentic', 'traditional',
        'nintendo', 'sony', 'toyota', 'honda', 'mitsubishi', 'panasonic'
    ]
    
    filtered_items = []
    debug_count = 0
    
    print(f"ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–‹å§‹: {len(items)}ä»¶ã®å•†å“ã‚’ç¢ºèª")
    
    # ã¾ãšæœ€åˆã®10ä»¶ã®å†…å®¹ã‚’ç¢ºèª
    print("\nğŸ“‹ æœ€åˆã®10ä»¶ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ä¾¡æ ¼ç¢ºèª:")
    for i, item in enumerate(items[:10], 1):
        if item:
            print(f"  {i}. {item.get('title', 'ä¸æ˜')[:60]}... | {item.get('price', 'ä¸æ˜')}")
    
    for i, item in enumerate(items):
        if not item:
            continue
            
        title = item.get('title', '').lower()
        price_str = item.get('price', '')
        keyword = item.get('keyword', '').lower()
        
        # ã‚¿ã‚¤ãƒˆãƒ«ãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
        if not title or title == "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜" or len(title) < 5:
            continue
        
        # æ—¥æœ¬é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        is_japanese = (
            any(indicator in title for indicator in japanese_indicators) or
            any(indicator in keyword for indicator in japanese_indicators)
        )
        
        # ä¾¡æ ¼ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        has_valid_price = True
        if price_str and price_str != "ä¾¡æ ¼ä¸æ˜":
            # $20.00 ã®ã‚ˆã†ãªä¾¡æ ¼ã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡º
            price_match = re.search(r'[\d,]+\.?\d*', str(price_str))
            if price_match:
                try:
                    price_value = float(price_match.group().replace(',', ''))
                    has_valid_price = price_value >= min_price
                except:
                    has_valid_price = True
        
        # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼ˆæœ€åˆã®5ä»¶ï¼‰
        if debug_count < 5:
            print(f"\n  ğŸ“‹ å•†å“ {debug_count + 1} è©³ç´°:")
            print(f"     ã‚¿ã‚¤ãƒˆãƒ«: {item.get('title', '')[:80]}...")
            print(f"     ä¾¡æ ¼: {price_str}")
            print(f"     æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}")
            matching_title_keywords = [kw for kw in japanese_indicators if kw in title]
            matching_search_keywords = [kw for kw in japanese_indicators if kw in keyword]
            print(f"     ã‚¿ã‚¤ãƒˆãƒ«å†…ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {matching_title_keywords}")
            print(f"     æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å†…: {matching_search_keywords}")
            print(f"     æ—¥æœ¬é–¢é€£åˆ¤å®š: {is_japanese}")
            print(f"     ä¾¡æ ¼åˆ¤å®š: {has_valid_price}")
            print(f"     â†’ è¿½åŠ : {is_japanese and has_valid_price}")
            debug_count += 1
        
        if is_japanese and has_valid_price:
            filtered_items.append(item)
    
    print(f"\nâœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Œäº†: {len(filtered_items)}ä»¶ãŒæ¡ä»¶ã«åˆè‡´")
    return filtered_items

def analyze_items(items):
    """
    å–å¾—ã—ãŸå•†å“ã‚’åˆ†æ
    """
    if not items:
        print("ğŸ“Š åˆ†æã™ã‚‹å•†å“ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    print(f"\nğŸ“Š å–å¾—å•†å“åˆ†æ (ç·æ•°: {len(items)}ä»¶)")
    print("=" * 50)
    
    # ä¾¡æ ¼å¸¯åˆ†æ
    prices = []
    price_unknown_count = 0
    
    for item in items:
        price_str = item.get('price', 'ä¾¡æ ¼ä¸æ˜')
        if price_str == "ä¾¡æ ¼ä¸æ˜":
            price_unknown_count += 1
            continue
            
        price_match = re.search(r'[\d,]+\.?\d*', price_str)
        if price_match:
            try:
                price = float(price_match.group().replace(',', ''))
                prices.append(price)
            except:
                price_unknown_count += 1
    
    print(f"ğŸ’° ä¾¡æ ¼æƒ…å ±:")
    print(f"  ä¾¡æ ¼å–å¾—æ¸ˆã¿: {len(prices)}ä»¶")
    print(f"  ä¾¡æ ¼ä¸æ˜: {price_unknown_count}ä»¶")
    
    if prices:
        print(f"  å¹³å‡ä¾¡æ ¼: ${sum(prices)/len(prices):.2f}")
        print(f"  æœ€é«˜ä¾¡æ ¼: ${max(prices):.2f}")
        print(f"  æœ€ä½ä¾¡æ ¼: ${min(prices):.2f}")
        print(f"  ä¸­å¤®å€¤: ${sorted(prices)[len(prices)//2]:.2f}")
        
        # ä¾¡æ ¼å¸¯åˆ†å¸ƒ
        price_ranges = {
            "$1-10": len([p for p in prices if 1 <= p <= 10]),
            "$11-50": len([p for p in prices if 11 <= p <= 50]),
            "$51-100": len([p for p in prices if 51 <= p <= 100]),
            "$101-500": len([p for p in prices if 101 <= p <= 500]),
            "$501-1000": len([p for p in prices if 501 <= p <= 1000]),
            "$1000+": len([p for p in prices if p > 1000])
        }
        
        print(f"\nğŸ’ ä¾¡æ ¼å¸¯åˆ†å¸ƒ:")
        for range_name, count in price_ranges.items():
            print(f"  {range_name}: {count}ä»¶")
    
    # äººæ°—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
    keyword_counts = {}
    for item in items:
        keyword = item.get('keyword', 'unknown')
        keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1
    
    print(f"\nğŸ”¥ äººæ°—æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:")
    for keyword, count in sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)[:5]:
        print(f"  {keyword}: {count}ä»¶")
    
    # é«˜é¡å•†å“ãƒˆãƒƒãƒ—5
    if prices:
        items_with_prices = [(item, price) for item, price in zip([item for item in items if item.get('price') != 'ä¾¡æ ¼ä¸æ˜'], prices) if price > 0]
        items_with_prices.sort(key=lambda x: x[1], reverse=True)
        
        print(f"\nğŸ’ é«˜é¡å•†å“ãƒˆãƒƒãƒ—5:")
        for i, (item, price) in enumerate(items_with_prices[:5], 1):
            title = item['title'][:50] + "..." if len(item['title']) > 50 else item['title']
            print(f"  {i}. ${price:.2f} - {title}")

def save_to_csv(items, filename="ebay_japanese_items.csv"):
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    """
    if not items:
        print("ğŸ’¾ ä¿å­˜ã™ã‚‹å•†å“ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    df = pd.DataFrame(items)
    df.to_csv(filename, index=False, encoding='utf-8-sig')
    print(f"ğŸ’¾ {len(items)}ä»¶ã®å•†å“ã‚’ '{filename}' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # ä¾¡æ ¼æƒ…å ±ã®çµ±è¨ˆã‚‚è¡¨ç¤º
    price_with_value = df[df['price'] != 'ä¾¡æ ¼ä¸æ˜']
    print(f"  ä¾¡æ ¼å–å¾—ç‡: {len(price_with_value)}/{len(items)} ({len(price_with_value)/len(items)*100:.1f}%)")

def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
    """
    print("ğŸš€ eBayå’Œé¢¨å•†å“ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹")
    print("=" * 50)
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦æœ‰åŠ¹åŒ–ï¼‰
    # extract_price_from_text.debug_mode = True
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
    session = get_ebay_session()
    if not session:
        print("âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—å¤±æ•—")
        return
    
    # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ï¼‰
    custom_keywords = ["japan vintage", "japanese antique"]  # ã“ã“ã‚’å¤‰æ›´å¯èƒ½
    
    # å•†å“æ¤œç´¢
    print("ğŸ” å•†å“æ¤œç´¢ä¸­...")
    items = search_japanese_items(session, custom_keywords, pages=2)
    
    if not items:
        print("âŒ å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # å’Œé¢¨å•†å“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    print("ğŸŒ å’Œé¢¨å•†å“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸­...")
    filtered_items = filter_japanese_items(items, min_price=5.0)
    
    print(f"âœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œ: {len(filtered_items)}ä»¶")
    
    # åˆ†æå®Ÿè¡Œ
    analyze_items(filtered_items)
    
    # CSVä¿å­˜
    save_to_csv(filtered_items)
    
    print("\nğŸ‰ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†ï¼")
    
    return filtered_items

# å®Ÿè¡Œ
if __name__ == "__main__":
    result = main()
